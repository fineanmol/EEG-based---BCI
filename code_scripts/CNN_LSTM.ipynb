{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84f1f7d7-aa2e-423c-ac65-a86c2c473035",
   "metadata": {},
   "source": [
    "# Title: CNN_LSTM Model (MSC/MPC Features)\n",
    "\n",
    "This notebook demonstrates how to train and evaluate a CNN_LSTM model on EEG data (processed via MSC/MPC features). It includes steps for data loading, augmentation, dimensionality reduction (PCA), training, confusion matrix visualization, per-class bar charts, and an accuracy comparison with/without PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23ff7934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import scipy.io\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import math\n",
    "\n",
    "# Create CNN_LSTM directory if it doesn't exist\n",
    "os.makedirs(\"CNN_LSTM\", exist_ok=True)\n",
    "\n",
    "# Choose device (GPU if available)\n",
    "device = (\n",
    "    \"mps\" if torch.backends.mps.is_available() \n",
    "    else \"cuda\" if torch.cuda.is_available() \n",
    "    else \"cpu\"\n",
    ")\n",
    "print(\"Using device:\", device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201dcff6-8619-4fbf-bbe9-31c4941536cd",
   "metadata": {},
   "source": [
    "# Loading EEG data\n",
    "This section loads the EEG datasets, merges them if necessary, and displays initial information about the data structures. We then define some variables and dictionaries related to the classification labels (words)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ea8e130b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading EEG data...\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading EEG data...\")\n",
    "import scipy.io\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv('EEG_data_subject4', sep=\"\\t\")  # example path\n",
    "df_imagined = pd.read_csv('EEG_data_subject3', sep=\"\\t\")\n",
    "df_imagined.drop([\"Time\"], axis=1, inplace=True)\n",
    "df_inner = pd.read_csv('EEG_data_subject4', sep=\"\\t\")\n",
    "df_inner.drop([\"Time\"], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89e85a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_imagined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e97cb85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_combined = pd.concat([df_imagined, df_inner])\n",
    "\n",
    "# Convert to numpy\n",
    "data = np.array(df_imagined)\n",
    "data = data.transpose()\n",
    "\n",
    "# Load labels (words)\n",
    "y_array = np.load(\"labels_word_list.npy\")\n",
    "\n",
    "print(f\"Shape of data_array: {data.shape}, Labels shape: {y_array.shape}\")\n",
    "print(\"First 10 labels:\", y_array[:10])\n",
    "\n",
    "# Dictionary of words to label indices\n",
    "num_dict = {\n",
    "    'date': 0, 'goose': 1, 'spruce': 2, 'knight': 3, 'juice': 4, 'moose': 5, 'night': 6,\n",
    "    'queen': 7, 'berry': 8, 'hedgehog': 9, 'water': 10, 'daughter': 11, 'gooseberry': 12,\n",
    "    'waterfowl': 13, 'wilderness': 14, 'relative': 15, 'watermelon': 16, 'caterpillar': 17,\n",
    "    'environment': 18, 'ambassador': 19\n",
    "}\n",
    "\n",
    "# Create reverse mapping\n",
    "word_dict = {v: k for k, v in num_dict.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cee206",
   "metadata": {},
   "source": [
    "# 2) Data Epoching / Segmenting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683589f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We break the EEG data into epochs of 256 samples, you are effectively segmenting the data into 1-second intervals.\n",
    "print(\"Epoching data...\")\n",
    "n=int(data.shape[1]/256)\n",
    "epoched_data=[]\n",
    "for i in range(n):\n",
    "    epoched_data.append(data[:,256*i:256*(i+1)])\n",
    "epoched_data=np.array(epoched_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e1cd2f-de1b-43ce-a154-5a5b47464fcb",
   "metadata": {},
   "source": [
    "# Shuffling / random permutation\n",
    "Ensures randomization of the epochs and their labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84efaaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply random permutation\n",
    "p=np.random.RandomState(seed=42).permutation(len(y_array))\n",
    "epoched_data=epoched_data[p]\n",
    "y_array=y_array[p]\n",
    "print(f\"Epoched data shape: {epoched_data.shape}\") #(num_epochs,num_channels,epoch_length)\n",
    "print(\"Shuffled y_array shape:\", y_array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9df3131",
   "metadata": {},
   "source": [
    "# Data Augmentation\n",
    "Creates additional “sub-epochs” by sliding windows within each original epoch.\n",
    "\n",
    "Here, we create overlapping sub‐epochs (128 samples each, with a certain overlap) to artificially increase the number of training examples. Then we replicate labels accordingly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c361110",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Augmenting data...\")\n",
    "augmented_data=[]\n",
    "n=epoched_data.shape[0]\n",
    "length=128\n",
    "overlap=32\n",
    "for i in range(n):\n",
    "    for j in range(0,length+1,overlap):\n",
    "        augmented_data.append(epoched_data[i][:,j:j+length])\n",
    "augmented_data=np.array(augmented_data)\n",
    "print(\"Augmented data shape:\", augmented_data.shape) #(num_epochs,num_channels,epoch_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2d3879",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoched_data=augmented_data\n",
    "print(f\"Augmented data shape: {epoched_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1244705a",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoched_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db8e097-a79d-4300-a8f8-56fdf7b03a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust Label for Augmented Data. i.e Replicate each label the appropriate number of times\n",
    "# You must replicate each label 5 times\n",
    "\n",
    "augmented_labels = []\n",
    "for label in y_array:\n",
    "    for _ in range(5):  # X= 5 Because from each epoch, we created 5 sub-epochs\n",
    "        augmented_labels.append(label)\n",
    "\n",
    "y_array = np.array(augmented_labels)\n",
    "print(f\"Augmented labels Y_shape: {y_array.shape}\")    # should now be (5000,)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f091798a",
   "metadata": {},
   "source": [
    "# Creating continuous data from epoched data\n",
    "\n",
    "We reshape/concatenate the epochs so we can perform subsequent filtering (alpha, beta, gamma extraction) using MNE functions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d175e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating continuous data from epoched data\n",
    "continuous_data=[]\n",
    "trials=epoched_data.shape[0]\n",
    "channels=epoched_data.shape[1]\n",
    "sample_size=epoched_data.shape[2]\n",
    "for i in range(channels):\n",
    "    continuous_data.append(epoched_data[:,i].reshape(trials*sample_size))\n",
    "continuous_data=np.array(continuous_data)\n",
    "print(\"Continuous data shape:\", continuous_data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2323f18c",
   "metadata": {},
   "source": [
    "# **Extracting Alpha, Beta, Gamma Bands with MNE from continuous data**\n",
    "\n",
    "We apply notch filtering at 60 Hz, downsample, and specifically extract alpha, beta, and gamma bands for each channel, then re‐epoch them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf402e23-e50b-4e2f-9d72-94db59ce8ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install mne --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fea1d8-8d53-4ed4-b29e-e9342edc74b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup MNE for filtering\n",
    "\n",
    "import mne\n",
    "sfreq=128\n",
    "ch_names=[\"F3\",\"FC5\",\"AF3\",\"F7\",\"T7\",\"P7\",\"O1\",\"O2\",\"P8\",\"T8\",\"F8\",\"AF4\",\"FC6\",\"F4\"] \n",
    "info=mne.create_info(ch_names,sfreq=sfreq)\n",
    "raw=mne.io.RawArray(continuous_data,info)\n",
    "raw.plot(scalings = 'auto');\n",
    "\n",
    "print(\"Filtering EEG bands...\")\n",
    "\n",
    "# Notch filter at 60 Hz\n",
    "raw.notch_filter(60,picks='all')\n",
    "\n",
    "# (Optional) downsampling\n",
    "raw.resample(120, npad='auto')\n",
    "\n",
    "# Extracting the alpha, beta, gamma from EEG\n",
    "# Uses MNE‐Python’s FIR filter to isolate each band.\n",
    "\n",
    "import mne.filter\n",
    "alpha_continuous=mne.filter.filter_data(continuous_data,128,8,12)\n",
    "beta_continuous=mne.filter.filter_data(continuous_data,128,12,30)\n",
    "gamma_continuous=mne.filter.filter_data(continuous_data,128,30,50)\n",
    "\n",
    "print(\"alpha_continuous shape:\", alpha_continuous.shape)\n",
    "\n",
    "# Re-epoch the filtered signals\n",
    "\n",
    "trial_duration=epoched_data.shape[2] #trial duration\n",
    "n=epoched_data.shape[0]\n",
    "\n",
    "alpha_epoched=[]\n",
    "beta_epoched=[]\n",
    "gamma_epoched=[]\n",
    "\n",
    "for i in range(n):\n",
    "    alpha_epoched.append(alpha_continuous[:,i*trial_duration:(i+1)*trial_duration])\n",
    "    beta_epoched.append(beta_continuous[:,i*trial_duration:(i+1)*trial_duration])\n",
    "    gamma_epoched.append(gamma_continuous[:,i*trial_duration:(i+1)*trial_duration])\n",
    "\n",
    "alpha_epoched=np.array(alpha_epoched)\n",
    "beta_epoched=np.array(beta_epoched)\n",
    "gamma_epoched=np.array(gamma_epoched)\n",
    "\n",
    "print(\"alpha_epoched shape:\", alpha_epoched.shape)  #(num_epochs,num_channels,epoch_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1c0dcb",
   "metadata": {},
   "source": [
    "# Feature Extraction Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c16a354",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "edfca630",
   "metadata": {},
   "source": [
    "# **Type 2: Feature Extraction (MPC & MSC)**\n",
    "\n",
    "We compute Mean Phase Coherence (MPC) and Magnitude Squared Coherence (MSC) for alpha, beta, gamma bands, and assemble them into a feature vector. This process can be computationally heavy, so a progress indicator (`print(i,end=' ')`) is shown.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc1cd0b",
   "metadata": {},
   "source": [
    "In this second technique, the features,  **mean phase coherence (MPC)** is extracted along with **magnitude-squared coherence (MSC)** from the augmented data \\citep{panachakel2021decoding}. MPC between two EEG channels is described as a measure of their phase synchronisation. The mean phase coherence (MPC) between two EEG signals with instantaneous phase difference $\n",
    "    \\phi(t)=\\phi_1(t)-\\phi_2(t)\n",
    "$ can be estimated via,\n",
    "\n",
    "$\n",
    "    \\lambda = \\frac{1}{N}\\Bigg|\\sum_{n=0}^{N-1}e^{j(\\hat{\\phi}_i(n))}\\Bigg|\n",
    "$\n",
    "where $\n",
    "    {(\\hat{\\phi}_i(n))}_{n=0}^{N-1}\n",
    "$ is the estimation of $\n",
    "    \\phi(t)\n",
    "$,\n",
    "where N is the number of samples,and the instantaneous phases are computed using Hilbert transform.\n",
    "Where as, if a pair of signals are in spectral domain, MSC computes the linear relationship between them. Hamming window is used for this process. Let the auto-spectral densities and the cross-spectral density  of $\n",
    "    x(t)\n",
    "$ and $\n",
    "    y(t)\n",
    "$  be denoted by $\n",
    "    P_{xx}(f)\n",
    "$, $\n",
    "    P_{yy}(f)\n",
    "$  and $\n",
    "    P_{xy}(f)\n",
    "$ respectively at frequency f. The MSC between them is given by:\n",
    "\n",
    "$\n",
    "    \\gamma _{xy}^{2} (f) = {{\\left\\vert {P_{xy} (f)} \\right\\vert^{2} } \\over {P_{xx} (f)P_{yy} (f)}} \n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908e3d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculation of hilbert array from augmented array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4805173-8237-403a-8e53-6553bb0cc19e",
   "metadata": {},
   "source": [
    "**MSC (Magnitude Squared Coherence)**:  Measures the strength of correlation between two EEG signals in the frequency domain.\n",
    "\n",
    "**MPC (Mean Phase Coherence)**:  Measures how well two EEG signals stay in phase over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140efc9a-53c1-4789-ae57-ab53a5c6c8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import hilbert , welch, csd, coherence\n",
    "\n",
    "def msc(arr1, arr2):\n",
    "    #Magnitude‐Squared Coherence (MSC)\n",
    "    #Measures the linear correlation in the frequency domain.\n",
    "    fs = 128\n",
    "    f, Cxy = coherence(arr1, arr2, fs=fs, window=\"hamm\", nperseg=8)\n",
    "    return np.mean(Cxy)\n",
    "\n",
    "def mpc(arr1, arr2):\n",
    "    #Mean Phase Coherence (MPC)\n",
    "    # Measures phase synchronization between two signals.\n",
    "    imag_1 = np.imag(hilbert(arr1))\n",
    "    imag_2 = np.imag(hilbert(arr2))\n",
    "    phase_1 = np.arctan2(imag_1, arr1, out=np.zeros_like(imag_1), where=arr1!=0)\n",
    "    phase_2 = np.arctan2(imag_2, arr2, out=np.zeros_like(imag_2), where=arr2!=0)\n",
    "    phase_diff = (phase_1 - phase_2)\n",
    "    return np.linalg.norm(np.sum(np.exp(1j*phase_diff))) / len(arr1)\n",
    "\n",
    "print(\"Calculating coherence matrices ...\")\n",
    "\n",
    "n = alpha_epoched.shape[0]\n",
    "m = alpha_epoched.shape[1]\n",
    "l=alpha_epoched.shape[2]\n",
    "\n",
    "# Initialize matrices\n",
    "mpc_alpha = np.zeros([n,m,m])\n",
    "mpc_beta  = np.zeros([n,m,m])\n",
    "mpc_gamma = np.zeros([n,m,m])\n",
    "\n",
    "msc_alpha = np.zeros([n,m,m])\n",
    "msc_beta  = np.zeros([n,m,m])\n",
    "msc_gamma = np.zeros([n,m,m])\n",
    "\n",
    "for i in range(n):\n",
    "    for j in range(m):\n",
    "        for k in range(m):\n",
    "            mpc_alpha[i][j][k] = mpc(alpha_epoched[i][j], alpha_epoched[i][k])\n",
    "            msc_alpha[i][j][k] = msc(alpha_epoched[i][j], alpha_epoched[i][k])\n",
    "\n",
    "            mpc_beta[i][j][k]  = mpc(beta_epoched[i][j],  beta_epoched[i][k])\n",
    "            msc_beta[i][j][k]  = msc(beta_epoched[i][j],  beta_epoched[i][k])\n",
    "\n",
    "            mpc_gamma[i][j][k] = mpc(gamma_epoched[i][j], gamma_epoched[i][k])\n",
    "            msc_gamma[i][j][k] = msc(gamma_epoched[i][j], gamma_epoched[i][k])\n",
    "    print(i, end=' ')\n",
    "\n",
    "print(\"\\nMPC/MSC calculations complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff73ef85-4ef3-49bb-adb7-0179ce704196",
   "metadata": {},
   "source": [
    "# **Creating the Feature Vector**\n",
    "\n",
    "We pack MPC (above the diagonal) and MSC (below the diagonal) for alpha, beta, gamma into a single 3D array, then flatten.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700b0ede-1171-4de6-b61f-422cb93610dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpc_alpha_copy=mpc_alpha\n",
    "mpc_beta_copy=mpc_beta\n",
    "mpc_gamma_copy=mpc_gamma\n",
    "\n",
    "msc_alpha_copy=msc_alpha\n",
    "msc_beta_copy=msc_beta\n",
    "msc_gamma_copy=msc_gamma\n",
    "\n",
    "print(\"MSC Copy Shape\",msc_alpha_copy.shape,\"\\nMPC Copy Shape\", mpc_alpha.shape)\n",
    "\n",
    "files=[mpc_alpha,mpc_beta,mpc_gamma,msc_alpha,msc_beta,msc_gamma]\n",
    "file_names=[\"mpc_alpha\",\"mpc_beta\",\"mpc_gamma\",\"msc_alpha\",\"msc_beta\",\"msc_gamma\"]\n",
    "\n",
    "#Saving the files\n",
    "part=\"01\"\n",
    "file_type=\"inner\"\n",
    "aug_type=\"non-aug\"\n",
    "\n",
    "for i in range(len(files)):\n",
    "    path=''+part+'/'+part+'_'+file_type+'/'+aug_type+'/'+file_names[i]+'.npy'\n",
    "    # np.save(path, files[i])  # Uncomment if you want to save to disk\n",
    "#loading the files\n",
    "\n",
    "# Example re-loading (disabled by default)\n",
    "for i in range(len(files)):\n",
    "    path=''+part+'/'+part+'_'+file_type+'/'+aug_type+'/'+file_names[i]+'.npy'\n",
    "    # files[i] = np.load(path) # Uncomment if you want to load from disk\n",
    "\n",
    "mpc_alpha = files[0]\n",
    "mpc_beta  = files[1]\n",
    "mpc_gamma = files[2]\n",
    "msc_alpha = files[3]\n",
    "msc_beta  = files[4]\n",
    "msc_gamma = files[5]\n",
    "\n",
    "print(\"MSC Shape\",msc_alpha.shape,\"\\nMPC Shape\", mpc_alpha.shape,\"\\n\")\n",
    "\n",
    "#Creating feature vectors\n",
    "print(\"\\nCreating feature vectors...\")\n",
    "\n",
    "n_1=msc_alpha.shape[0]\n",
    "m_1=msc_alpha.shape[1]\n",
    "x_array_2=np.zeros([n_1,m_1,m_1,3])\n",
    "\n",
    "\n",
    "print(\"mpc_alpha shape:\", mpc_alpha.shape)\n",
    "print(\"mpc_beta shape:\", mpc_beta.shape)\n",
    "print(\"mpc_gamma shape:\", mpc_gamma.shape)\n",
    "\n",
    "print(\"msc_alpha shape:\", msc_alpha.shape)\n",
    "print(\"msc_beta shape:\", msc_beta.shape)\n",
    "print(\"msc_gamma shape:\", msc_gamma.shape)\n",
    "\n",
    "for i in range(n_1):\n",
    "    for j in range(m_1):\n",
    "        for k in range(m_1):\n",
    "            if j<k:\n",
    "                x_array_2[i][j][k]=[mpc_alpha[i][j][k],mpc_beta[i][j][k],mpc_gamma[i][j][k]]\n",
    "            elif j>k:\n",
    "                x_array_2[i][j][k]=[msc_alpha[i][j][k],msc_beta[i][j][k],msc_gamma[i][j][k]]\n",
    "\n",
    "\n",
    "\n",
    "# Reshape to 2D\n",
    "a=x_array_2.reshape(n_1,m_1*m_1*3)\n",
    "\n",
    "# remove the zero diagonal\n",
    "a=a[a!=0.0]\n",
    "a.shape\n",
    "x_array_2=a.reshape(n_1,m_1*m_1*3-m_1*3)\n",
    "\n",
    "print(\"Final feature shape (x_array_2):\", x_array_2.shape)\n",
    "\n",
    "# Save X, Y if desired\n",
    "# np.save(f\"{part}/{part}_{file_type}_X.npy\", x_array_2)\n",
    "# np.save(f\"{part}/{part}_{file_type}_Y.npy\", y_array)\n",
    "\n",
    "x_array = x_array_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f4ba4f-eb34-4d23-a370-38ac590ac407",
   "metadata": {},
   "source": [
    "# Reshaping x_array for a CNN_LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb0c73d-3d35-455d-969b-fb33664510ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "N, channels, time = epoched_data.shape  # e.g. (1000, 14, 128)\n",
    "\n",
    "\n",
    "# Prepare data for CNN_LSTM model\n",
    "print(\"Preparing data for CNN_LSTM model...\")\n",
    "X_seq = np.transpose(epoched_data, (0, 2, 1))  # => (N, 128, 14)\n",
    "\n",
    "\n",
    "print(\"X_seq shape:\", X_seq.shape)       # (1000, 128, 14)\n",
    "print(\"y_array shape:\", y_array.shape)   # (1000,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7f33e4-1183-4301-97a1-c6219a057b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "N, F = x_array.shape\n",
    "seq_len = 1\n",
    "input_dim = F\n",
    "\n",
    "# Reshape from (N, F) -> (N, 1, F)\n",
    "X_seq = x_array.reshape(N, seq_len, input_dim)\n",
    "\n",
    "print(\"X_seq shape:\", X_seq.shape)  # (N, 1, F)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a45565",
   "metadata": {},
   "source": [
    "**In order to reduce the dimension of the feature vector Principal component analysis (PCA) was used.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af57e3f",
   "metadata": {},
   "source": [
    "# **Principal component analysis (PCA) / Standardization**\n",
    "Standard scaling is also used to zero‐mean/unit‐variance the features.\n",
    "We apply PCA to capture 95% variance. This yields the “with PCA” scenario. We will compare it to a “without PCA” scenario later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14779617",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Let's store a copy of x_array BEFORE PCA for the no-PCA scenario\n",
    "x_array_no_pca = x_array.copy()\n",
    "\n",
    "print(\"Applying PCA for feature reduction...\")\n",
    "pca = PCA(0.95)\n",
    "pca.fit(x_array)\n",
    "x_array_pca = pca.transform(x_array)\n",
    "\n",
    "print(\"After PCA, shape:\", x_array_pca.shape)\n",
    "print(\"Without PCA, shape:\", x_array_no_pca.shape)\n",
    "print(\"Labels shape:\", y_array.shape)\n",
    "\n",
    "# We'll do 2 separate runs below:\n",
    "# 1) x_array_pca => \"with PCA\"\n",
    "# 2) x_array_no_pca => \"without PCA\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92cd451-8590-4d46-8461-7baa8c0399d9",
   "metadata": {},
   "source": [
    "# **Building a PyTorch Dataset & DataLoader**\n",
    "\n",
    "We create a custom dataset class for our (X, y) data and split into train/val/test sets.  \n",
    "We’ll define a helper function to build the dataset for either PCA or no‐PCA inputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff800c2-1e03-4b9b-8bc8-c728a31045de",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_flattened = data.reshape(data.shape[0], -1)  # Shape: (5000, 14 * 128)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=71)\n",
    "data_pca = pca.fit_transform(data_flattened)  # Shape: (5000, 71)\n",
    "\n",
    "# Reshape data for CNN-LSTM input (num_samples, sequence_length, num_features)\n",
    "data_seq = data.reshape(data.shape[0], data.shape[2], data.shape[1])  # Shape: (5000, 128, 14)\n",
    "data_pca_seq = data_pca.reshape(data_pca.shape[0], 1, data_pca.shape[1])  # Shape: (5000, 1, 71)\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_seq, labels, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=42)\n",
    "\n",
    "X_train_pca, X_test_pca, y_train_pca, y_test_pca = train_test_split(data_pca_seq, labels, test_size=0.2, random_state=42)\n",
    "X_train_pca, X_val_pca, y_train_pca, y_val_pca = train_test_split(X_train_pca, y_train_pca, test_size=0.125, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dbdbe1-7375-4c81-8abc-9b9847676997",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install torch torchvision torchaudio --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9dc9d39-8057-4c0b-abf7-114e96ccff8e",
   "metadata": {},
   "source": [
    "# Define the CNN-LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfae2b3-3142-4c56-89c6-9c787efbe381",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class CNN_LSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, num_classes, kernel_size=3, stride=1, padding=1):\n",
    "        super(CNN_LSTM, self).__init__()\n",
    "        \n",
    "        # CNN layers\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=input_dim, out_channels=32, kernel_size=kernel_size, stride=stride, padding=padding),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "            nn.Conv1d(in_channels=32, out_channels=64, kernel_size=kernel_size, stride=stride, padding=padding),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        # LSTM layers\n",
    "        self.lstm = nn.LSTM(input_size=64, hidden_size=hidden_dim, num_layers=num_layers, batch_first=True)\n",
    "        \n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # CNN\n",
    "        x = self.cnn(x)\n",
    "        \n",
    "        # Permute for LSTM input (batch_size, seq_len, features)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        \n",
    "        # LSTM\n",
    "        h_lstm, _ = self.lstm(x)\n",
    "        \n",
    "        # Fully connected layer\n",
    "        out = self.fc(h_lstm[:, -1, :])\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2424ecd0-6e64-492b-a7d9-03f96a34f249",
   "metadata": {},
   "source": [
    "## Define the Dataset and DataLoader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28e0f68-3b9b-4959-9ec5-3bb484d47f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = EEGDataset(X_train, y_train)\n",
    "val_dataset = EEGDataset(X_val, y_val)\n",
    "test_dataset = EEGDataset(X_test, y_test)\n",
    "\n",
    "train_dataset_pca = EEGDataset(X_train_pca, y_train_pca)\n",
    "val_dataset_pca = EEGDataset(X_val_pca, y_val_pca)\n",
    "test_dataset_pca = EEGDataset(X_test_pca, y_test_pca)\n",
    "\n",
    "# Create dataloaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "train_loader_pca = DataLoader(train_dataset_pca, batch_size=batch_size, shuffle=True)\n",
    "val_loader_pca = DataLoader(val_dataset_pca, batch_size=batch_size, shuffle=False)\n",
    "test_loader_pca = DataLoader(test_dataset_pca, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2c0293-c42c-453c-8a89-2260f579abac",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f6606b-d842-4aa3-ba89-bb5fbb79df9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}, Val Loss: {val_loss/len(val_loader)}, Val Acc: {100 * correct / total}%')\n",
    "\n",
    "# Initialize the model\n",
    "input_dim = X_train.shape[2]  # Number of features (channels)\n",
    "hidden_dim = 128\n",
    "num_layers = 2\n",
    "num_classes = len(np.unique(labels))\n",
    "\n",
    "model = CNN_LSTM(input_dim, hidden_dim, num_layers, num_classes)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933ab8da-8d8f-45e7-a3f1-7387c55759dd",
   "metadata": {},
   "source": [
    "# **Evaluate the Model on Test Data**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8627b35-4982-4f6d-91b0-1d9ceeb922d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    print(f'Test Accuracy: {100 * correct / total}%')\n",
    "\n",
    "# Evaluate the model\n",
    "evaluate_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28776bb5-1943-4133-8012-e6670b7cbcd6",
   "metadata": {},
   "source": [
    "# Repeat for PCA Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd977c1-7019-44a6-b2e5-b95ed508abd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model for PCA data\n",
    "input_dim_pca = X_train_pca.shape[2]  # Number of features after PCA\n",
    "model_pca = CNN_LSTM(input_dim_pca, hidden_dim, num_layers, num_classes)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion_pca = nn.CrossEntropyLoss()\n",
    "optimizer_pca = optim.Adam(model_pca.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model on PCA data\n",
    "train_model(model_pca, train_loader_pca, val_loader_pca, criterion_pca, optimizer_pca, num_epochs=20)\n",
    "\n",
    "# Evaluate the model on PCA data\n",
    "evaluate_model(model_pca, test_loader_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cf108f-3c66-4afa-911f-f39120a3b492",
   "metadata": {},
   "source": [
    "# **Compare Result**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bc3efc-875b-48fa-be4d-ea31abad5fd8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Confusion Matrix for Non-PCA Data\n",
    "def plot_confusion_matrix(model, test_loader):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot()\n",
    "    plt.show()\n",
    "\n",
    "# Plot confusion matrix for Non-PCA data\n",
    "plot_confusion_matrix(model, test_loader)\n",
    "\n",
    "# Plot confusion matrix for PCA data\n",
    "plot_confusion_matrix(model_pca, test_loader_pca)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# -*- coding: utf-8 -*-",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
